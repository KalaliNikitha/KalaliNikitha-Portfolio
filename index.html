<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <meta name="description" content="Portfolio of Nikitha Kalali" />
    <meta name="keywords" content="Data Engineer, Portfolio, Data Analysis, Data Visualization" />
    <title>Nikitha Kalali's Portfolio</title>
    <link rel="stylesheet" href="assets/css/main.css" />
    <style>
        body {
            background-color: #121212;
            color: white;
            font-family: 'Times New Roman', Times, serif;
            margin: 0;
            padding: 0;
        }

        header {
            background-color: #1f1f1f;
            padding: 20px;
            text-align: center;
        }

        h1 {
            color: #a5d8ff;
            margin: 0;
            font-size: 3em;
        }

        h2, h3, h4 {
            color: #a5d8ff;
            font-size: 2em;
            padding-bottom: 15px;
            text-align: center;
            margin-top: 0;
            width: 100%;
        }

        /* Style for subheadings */
        .subheading {
            color: #ffffff;
            font-size: 1.4em;
            font-weight: bold;
            margin-top: 15px;
            margin-bottom: 5px;
            width: 100%;
        }

        section {
            padding: 20px;
            margin: 20px auto;
            background-color: #1f1f1f;
            border-radius: 5px;
            box-shadow: 0 2px 10px rgba(255, 255, 255, 0.1);
            display: flex;
            flex-direction: column;
            align-items: center;
            text-align: justify;
            max-width: 900px;
        }

        .about-text {
            color: #ccc;
            max-width: 800px;
            text-align: justify;
            margin: 0 auto;
        }

        .skills-list {
            list-style-type: none;
            padding: 0;
            text-align: justify;
            width: 100%;
        }

        .skills-list li {
            margin: 5px 0;
        }

        .white-heading {
            color: #f0f5f390;
            font-size: 1.2em;
        }

        .profile-image {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            margin: 20px auto;
            display: block;
        }

        .project-section {
            text-align: center;
            color: #a5d8ff;
            flex-direction: column;
        }

        .project-section h3 {
            font-size: 2em;
            width: 100%;
        }

        .project-description {
            color: #ffffff;
            text-align: justify;
            padding: 10px;
            margin: 0 auto;
        }

        .about-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            width: 100%;
        }

        footer {
            background-color: #1f1f1f;
            color: #ccc;
            padding: 10px;
            text-align: center;
        }
    </style>
</head>

<body>
    <header>
        <h1>Nikitha Kalali</h1>
        <p>Data Engineer</p>
    </header>

    <section id="about">
        <h2>About Me</h2>
        <div class="about-container">
            <img src="imageme.jpg" alt="Nikitha Kalali" class="profile-image">
            <div class="about-text">
                <p>Hi, I am Nikitha Kalali. My path in the data world began at Sigma Software, where I first immersed myself in the fundamentals of data management. There, I built ETL processes from the ground up, working with Apache Kafka to enable real-time data streaming. I learned to transform messy, unstructured data into clean, usable formats – a skill that would prove invaluable throughout my career.</p>
                <p>As my expertise grew, so did the complexity of my projects. I found myself designing database schemas across multiple platforms and implementing data architecture solutions that enhanced information flow across systems. This early experience taught me how to think holistically about data ecosystems.</p>
                <p>My journey continued at Amazon, where I stepped into the world of financial data analytics. Here, I tackled massive datasets, optimizing SQL queries and building automated quality checks. I enjoyed creating interactive dashboards that brought data to life for business users. The fast-paced environment pushed me to develop more efficient solutions, leading to my promotion to Senior Associate.</p>
                <p>In my elevated role, I partnered with HR and engineering teams to optimize data pipelines and ensure reliable payroll processing. I engineered scalable solutions using AWS cloud technologies, learning to balance performance with data quality. These experiences deepened my understanding of how data directly impacts business operations.</p>
                <p>Throughout this journey, I've evolved from someone who simply processed data to a professional who architects solutions that drive business value. My experience spans the full data lifecycle – from collection and storage to transformation and visualization – always focused on uncovering the stories hidden within the numbers.</p>
            </div>
        </div>
    </section>

    <section id="skills">
        <h2>Technical Skills</h2>
        <div class="about-text">
            <ul class="skills-list">
                <li><strong>Programming Languages:</strong> Python, Java, R, SAS, MATLAB, HTML/CSS, JavaScript, C++.</li>
                <li><strong>Big Data Technologies:</strong> Apache Spark, PySpark, Databricks.</li>
                <li><strong>Database/Data Technologies:</strong> SQL, T-SQL, PostgreSQL, MySQL, Oracle, MongoDB.</li>
                <li><strong>Machine Learning & AI Frameworks:</strong> TensorFlow, Keras, PyTorch.</li>
                <li><strong>Cloud Platforms:</strong> AWS, Microsoft Azure, GCP.</li>
                <li><strong>Version Control Systems:</strong> Git, Jenkins.</li>
                <li><strong>Data Visualization Tools:</strong> Tableau, PowerBI, Looker, Excel, DAX, MicroStrategy.</li>
                <li><strong>Data Warehousing:</strong> Snowflake, AWS Redshift, Data Lakes.</li>
                <li><strong>ETL and Workflow Tools:</strong> AWS Glue, Alteryx, SSIS, Azure Data Factory, Informatica-PowerCenter, Talend.</li>
            </ul>
        </div>
    </section>

    <!-- Project Section -->
    <section id="project" class="project-section">
        <h3>Project: Optimizing the Inventory</h3>
        <p class="project-description">This project focuses on streamlining the inventory management system to improve efficiency, reduce costs, and improve order accuracy by forecasting demand and automating reorder processes.</p>
    </section>

    <section id="techniques">
        <h2>Techniques Used in Project</h2>
        <div class="about-text">
            <ul class="skills-list">
                <li><strong>Predictive Modeling:</strong> XGBoost, Random Forest, Gradient Boosting, LightGBM</li>
                <li><strong>Time Series Analysis:</strong> ARIMA, SARIMA, Exponential Smoothing</li>
                <li><strong>Classification Models:</strong> Logistic Regression, Decision Tree, K-Nearest Neighbors</li>
                <li><strong>Feature Engineering:</strong> PCA, One-Hot Encoding, Feature Scaling</li>
                <li><strong>Statistical Testing:</strong> ANOVA, T-tests, Chi-Square Tests</li>
                <li><strong>Optimization Techniques:</strong> Hyperparameter Tuning, Grid Search</li>
            </ul>
        </div>
    </section>

    <section id="eda">
        <h2>Exploratory Data Analysis (EDA)</h2>
        <div class="about-text">
            <p>Exploratory Data Analysis (EDA) plays a seminal role in examining data and serving as the very foundation for further modelling efforts. The purpose of EDA is to spot patterns, trends, and relationships among the data. Afterwards, the identified patterns, trends, and relationships aid the researcher to develop effective analytical strategies. The exploration in this initial step helps to understand the relationship between different dimensions of the dataset and make decisions regarding modeling later.</p>
            <p><a href="https://github.com/KalaliNikitha/KalaliNikitha-Portfolio.git" target="_blank">View EDA</a></p>
        </div>
    </section>

    <section id="methodology">
        <h2>Methodology</h2>
        <div class="about-text">
            <p>The aim is to describe the forecasting methods used in our study. All the models are trained and validated by an 80/20 split.</p>
            
            <div class="subheading">SARIMA Model</div>
            <p>The SARIMA model was applied to capture seasonal patterns in demand, supporting inventory management by predicting spikes and dips in sales.</p>

            <div class="subheading">Sales Forecasting</div>
            <p>Regression Models: Linear Regression, Random Forest, Gradient Boosting, K-Neighbors, XGBoost, and LightGBM provided a range of approaches, each optimized through hyperparameter tuning to forecast sales trends accurately.</p>

            <div class="subheading">Late Delivery</div>
            <p>Classification models (Logistic Regression, Decision Tree, Random Forest, etc.) were evaluated for delivery predictions, with Random Forest and Logistic Regression showing high accuracy in distinguishing outcomes.</p>

            <div class="subheading">Fraud Detection</div>
            <p>Models like Random Forest and XGBoost achieved near-perfect accuracy in fraud detection, with metrics such as ROC-AUC confirming high reliability.</p>

            <div class="subheading">Customer Segmentation</div>
            <p>RFM (Recency, Frequency, Monetary) analysis categorized customers by purchasing behavior, enabling targeted engagement for different loyalty segments.</p>

            <p><a href="https://github.com/KalaliNikitha/KalaliNikitha-Portfolio.git" target="_blank">View Methodology</a></p>
        </div>
    </section>

    <section id="results">
        <h2>Final Results</h2>
        <div class="about-text">
            <p>Sales Forecasting Models and Evaluation Metrics:</p>
            
            <div class="subheading">SARIMA Results</div>
            <p>Used for short-term demand forecasting, capturing seasonal trends but limited in handling volatility.</p>

            <div class="subheading">Regression Results</div>
            <p>Linear Regression, Gradient Boosting, Lasso, Ridge, ElasticNet, and AdaBoost were used, with Linear Regression showing the highest R² score, though potentially overfitting.</p>

            <div class="subheading">Safety Stock</div>
            <p>Calculated to prevent stockouts, optimizing inventory by adjusting stock levels based on sales forecasts.</p>

            <div class="subheading">Delivery Prediction</div>
            <p>Classification Models: Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and AdaBoost were evaluated; Logistic Regression showed the best accuracy, with Random Forest and AdaBoost also performing well.</p>

            <div class="subheading">Fraud Models</div>
            <p>Models Used: Logistic Regression, Random Forest, Gradient Boosting, K-Nearest Neighbors, Decision Tree, and XGBoost all achieved high accuracy, with Random Forest showing near-perfect precision.</p>

            <div class="subheading">Evaluation</div>
            <p>Confusion Matrix and Precision-Recall Curves helped assess model sensitivity and specificity in fraud detection.</p>

            <div class="subheading">Customer Segments</div>
            <p>Customer Segmentation: RFM analysis segmented customers by recency, frequency, and monetary value into groups like "Loyal Customers" and "Need Attention" to inform targeted engagement.</p>

            <p><a href="https://github.com/KalaliNikitha/KalaliNikitha-Portfolio.git" target="_blank">View Results</a></p>
        </div>
    </section>

    <footer>
        <p>&copy; 2024 Nikitha Kalali. All rights reserved.</p>
    </footer>
</body>

</html>
