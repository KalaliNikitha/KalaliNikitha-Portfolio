<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <meta name="description" content="Portfolio of Nikitha Kalali" />
    <meta name="keywords" content="Data Engineer, Portfolio, Data Analysis, Data Visualization" />
    <title>Nikitha Kalali's Portfolio</title>
    <link rel="stylesheet" href="assets/css/main.css" />
    <style>
        body {
            background-color: #121212; 
            color: white;
            font-family: 'Times New Roman', Times, serif;
            margin: 0;
            padding: 0;
        }

        header {
            background-color: #1f1f1f; 
            padding: 20px;
            text-align: center;
        }

        h1 {
            color: #f0f5f390;
            margin: 0;
        }

        section {
            padding: 20px;
            margin: 20px;
            background-color: #1f1f1f;
            border-radius: 5px;
            box-shadow: 0 2px 10px rgba(255, 255, 255, 0.1);
        }

        h2 {
            color: #f0f5f390;
            padding-bottom: 5px;
        }

        .about-container {
            display: flex;
            align-items: flex-start;
            justify-content: flex-start;
        }

        .profile-image {
            width: 100px;
            height: 130px;
            border-radius: 50%;
            object-fit: cover;
            margin-right: 20px;
        }

        .about-text {
            color: #ccc;
            max-width: 600px;
            text-align: justify;
        }

        .skills-list, .projects-list {
            list-style: none;
            padding: 0;
        }

        .skills-list li, .projects-list li {
            margin: 5px 0;
            color: #bbb;
        }

        footer {
            text-align: center;
            margin-top: 20px;
            padding: 10px;
            background-color: #1f1f1f;
            color: white;
        }

        .project-container {
            display: flex;
            flex-direction: column;
            align-items: center;
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            border: 1px solid #444;
            border-radius: 8px;
            background-color: rgba(255, 255, 255, 0.1);
        }

        .project-link {
            color: #007BFF;
            text-decoration: none;
        }

        .project-link:hover {
            text-decoration: underline;
        }

        /* Updated classes for headings and descriptions */
        .white-heading {
            color: white; /* White color for side headings and names */
        }

        .gray-description {
            color: #ccc; /* Gray color for descriptions */
        }
    </style>
</head>

<body>

    <header>
        <h1>Nikitha Kalali</h1>
        <p>Data Engineer</p>
    </header>

    <section id="about">
        <h2>About Me</h2>
        <div class="about-container">
            <img src="imageme.jpg" alt="Nikitha Kalali" class="profile-image">
            <div class="about-text">
                <p>Hi, I am Nikitha Kalali My path in the data world began at Sigma Software, where I first immersed myself in the fundamentals of data management. There, I built ETL processes from the ground up, working with Apache Kafka to enable real-time data streaming. I learned to transform messy, unstructured data into clean, usable formats – a skill that would prove invaluable throughout my career.
As my expertise grew, so did the complexity of my projects. I found myself designing database schemas across multiple platforms and implementing data architecture solutions that enhanced information flow across systems. This early experience taught me how to think holistically about data ecosystems.
My journey continued at Amazon, where I stepped into the world of financial data analytics. Here, I tackled massive datasets, optimizing SQL queries and building automated quality checks. I enjoyed creating interactive dashboards that brought data to life for business users. The fast-paced environment pushed me to develop more efficient solutions, leading to my promotion to Senior Associate.
In my elevated role, I partnered with HR and engineering teams to optimize data pipelines and ensure reliable payroll processing. I engineered scalable solutions using AWS cloud technologies, learning to balance performance with data quality. These experiences deepened my understanding of how data directly impacts business operations.
My passion for learning led me to pursue a Master's in Business Analytics at the University of North Texas, where I expanded my theoretical knowledge and practical skills in data mining, machine learning, and cloud computing.
Now, in my current contract position, I'm handling massive data ingestion across diverse sources and cloud platforms. I've automated ETL processes that transformed hours-long tasks into seconds, orchestrated complex batch processing operations, and enhanced predictive analytics that directly influence business strategy. I've become adept at leveraging a wide range of tools – from Python and SQL to cloud services like AWS and GCP – to transform raw data into meaningful insights.
Throughout this journey, I've evolved from someone who simply processed data to a professional who architects solutions that drive business value. My experience spans the full data lifecycle – from collection and storage to transformation and visualization – always focused on uncovering the stories hidden within the numbers</p>
            </div>
        </div>
    </section>

    <section id="Project">
        <h2>My Project</h2>
        <div class="project">
            <h3 class="white-heading">Inventory Optimization</h3>
            <p><strong class="white-heading">Technologies:</strong> Python, Pandas, Matplotlib</p>
            <a href="https://github.com/KalaliNikitha/KalaliNikitha-Portfolio.git" target="_blank" class="project-link">Code</a>
        </div>
    </section>

    <section id="eda">
        <h2>Exploratory Data Analysis (EDA)</h2>
        <div class="project-container">
            <h3 class="white-heading">Exploratory Data Analysis</h3>
            <p class="gray-description">Exploratory Data Analysis (EDA) plays a seminal role in examining data and serving as the very foundation for further 
                modelling efforts. The purpose of EDA is to spot patterns, trends, and relationships among the data. Afterwards, the 
                identified patterns, trends, and relationships aid the researcher to develop effective analytical strategies. The 
                exploration in this initial step helps to understand the relationship between different dimensions of the dataset and 
                make decisions regarding modeling later.</p>
            <p>
                <a href="https://github.com/KalaliNikitha/KalaliNikitha-Portfolio.git" target="_blank" class="project-link">View EDA</a>
            </p>
        </div>
    </section>

    <section id="methodology">
        <h2>Methodology</h2>
        <div class="project-container">
            <h3 class="white-heading">Methodology and Metrics</h3>
            <p class="gray-description">The aim is to describe the forecasting methods used in our study. All the models are trained and validated by 80/20 split.</p>
            <p><strong class="white-heading">Demand Forecasting with SARIMA:</strong><br>
            <span class="gray-description">The SARIMA model was applied to capture seasonal patterns in demand, supporting inventory management by predicting spikes and dips in sales.</span></p>
            <p><strong class="white-heading">Sales Forecasting Models:</strong><br>
            <span class="gray-description">Regression Models: Linear Regression, Random Forest, Gradient Boosting, K-Neighbors, XGBoost, and LightGBM provided a range of approaches, each optimized through hyperparameter tuning to forecast sales trends accurately.</span></p>
            <p><strong class="white-heading">Late Delivery Prediction:</strong><br>
            <span class="gray-description">Classification models (Logistic Regression, Decision Tree, Random Forest, etc.) were evaluated for delivery predictions, with Random Forest and Logistic Regression showing high accuracy in distinguishing outcomes.</span></p>
            <p><strong class="white-heading">Fraud Detection:</strong><br>
            <span class="gray-description">Models like Random Forest and XGBoost achieved near-perfect accuracy in fraud detection, with metrics such as ROC-AUC confirming high reliability.</span></p>
            <p><strong class="white-heading">Customer Segmentation with RFM Analysis:</strong><br>
            <span class="gray-description">RFM (Recency, Frequency, Monetary) analysis categorized customers by purchasing behavior, enabling targeted engagement for different loyalty segments.</span></p>
            <p>
                <a href="https://github.com/KalaliNikitha/KalaliNikitha-Portfolio.git" target="_blank" class="project-link">View Methodology</a>
            </p>
        </div>
    </section>
    
    <section id="results">
        <h2>Final Results</h2>
        <div class="project-container">
            <h3 class="white-heading">Results and Conclusion</h3>
            <p><strong class="white-heading">Sales Forecasting Models and Evaluation Metrics</strong><br>
                <span class="gray-description">SARIMA Model: Used for short-term demand forecasting, capturing seasonal trends but limited in handling volatility.</span><br>
                <span class="gray-description">Regression Models: Linear Regression, Gradient Boosting, Lasso, Ridge, ElasticNet, and AdaBoost were used, with Linear Regression showing the highest R² score, though potentially overfitting.</span><br>
                <span class="gray-description">Safety Stock and Reorder Threshold: Calculated to prevent stockouts, optimizing inventory by adjusting stock levels based on sales forecasts.</span>
            </p>
            <p><strong class="white-heading">Late Delivery Prediction</strong><br>
                <span class="gray-description">Classification Models: Logistic Regression, Decision Tree, Random Forest, K-Nearest Neighbors, and AdaBoost were evaluated; Logistic Regression showed the best accuracy, with Random Forest and AdaBoost also performing well.</span>
            </p>
            <p><strong class="white-heading">Fraud Detection Models</strong><br>
                <span class="gray-description">Models Used: Logistic Regression, Random Forest, Gradient Boosting, K-Nearest Neighbors, Decision Tree, and XGBoost all achieved high accuracy, with Random Forest showing near-perfect precision.</span><br>
                <span class="gray-description">Evaluation: Confusion Matrix and Precision-Recall Curves helped assess model sensitivity and specificity in fraud detection.</span>
            </p>
            <p><strong class="white-heading">RFM Analysis and Customer Segmentation</strong><br>
                <span class="gray-description">Customer Segmentation: RFM analysis segmented customers by recency, frequency, and monetary value into groups like "Loyal Customers" and "Need Attention" to inform targeted engagement.</span>
            </p>
            <p>
                <a href="https://github.com/KalaliNikitha/KalaliNikitha-Portfolio.git" target="_blank" class="project-link">View Results</a>
            </p>
        </div>
    </section>

    <section id="contact">
        <h2>Contact</h2>
        <p class="gray-description">If you'd like to get in touch, feel free to connect with me on <a href="https://www.linkedin.com/in/kalalinikitha/" target="_blank" class="project-link">LinkedIn</a>!</p>
    </section>

    <footer>
        <p>&copy; 2024 Nikitha Kalali. All rights reserved.</p>
    </footer>
</body>

</html>
